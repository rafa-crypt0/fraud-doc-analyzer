{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get -qq update\n",
        "!apt-get -qq install -y tesseract-ocr tesseract-ocr-por poppler-utils\n",
        "!pip -q install pytesseract pdf2image pymupdf pillow python-dateutil pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSjZqFJHwTzO",
        "outputId": "3c410005-c633-43da-9b64-ca0249a5c58a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io, re, json, math, hashlib\n",
        "from datetime import datetime, date\n",
        "\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_bytes\n",
        "import fitz  # pymupdf\n",
        "from dateutil import parser as dateparser\n",
        "from google.colab import files\n",
        "\n",
        "def sha256_bytes(b: bytes) -> str:\n",
        "    return hashlib.sha256(b).hexdigest()\n",
        "\n",
        "uploaded = files.upload()\n",
        "file_name = next(iter(uploaded.keys()))\n",
        "file_bytes = uploaded[file_name]\n",
        "doc_hash = sha256_bytes(file_bytes)\n",
        "\n",
        "print(\"Arquivo:\", file_name)\n",
        "print(\"SHA256:\", doc_hash[:16], \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "bpk-acMwwe31",
        "outputId": "6bcb2f30-6e8a-4f03-d788-2e16912eec5c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4d449dc5-e191-41e5-a415-eedb20b76e12\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4d449dc5-e191-41e5-a415-eedb20b76e12\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving documento_fraude_simulada.pdf to documento_fraude_simulada.pdf\n",
            "Arquivo: documento_fraude_simulada.pdf\n",
            "SHA256: a5968e5f7fa1e988 ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_offline(file_name: str, file_bytes: bytes, lang=\"por\"):\n",
        "    ext = file_name.lower().split(\".\")[-1]\n",
        "    pages_text = []\n",
        "    used = None\n",
        "\n",
        "    if ext == \"pdf\":\n",
        "        # 1) tenta extrair texto digital (sem OCR)\n",
        "        try:\n",
        "            doc = fitz.open(stream=file_bytes, filetype=\"pdf\")\n",
        "            digital_text = []\n",
        "            for i in range(len(doc)):\n",
        "                digital_text.append(doc[i].get_text(\"text\"))\n",
        "            digital_text = \"\\n\".join(digital_text).strip()\n",
        "            if len(digital_text) >= 300:  # heurística: tem texto mesmo\n",
        "                used = \"PDF_DIGITAL_TEXT\"\n",
        "                return {\"text\": digital_text, \"method\": used, \"page_count\": len(doc)}\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # 2) fallback: OCR em páginas renderizadas\n",
        "        images = convert_from_bytes(file_bytes, dpi=250)\n",
        "        for img in images:\n",
        "            t = pytesseract.image_to_string(img, lang=lang)\n",
        "            pages_text.append(t)\n",
        "        used = \"PDF_OCR\"\n",
        "        return {\"text\": \"\\n\".join(pages_text).strip(), \"method\": used, \"page_count\": len(images)}\n",
        "\n",
        "    else:\n",
        "        # imagem\n",
        "        img = Image.open(io.BytesIO(file_bytes)).convert(\"RGB\")\n",
        "        text = pytesseract.image_to_string(img, lang=lang)\n",
        "        used = \"IMAGE_OCR\"\n",
        "        return {\"text\": text.strip(), \"method\": used, \"page_count\": 1}\n",
        "\n",
        "doc_ocr = extract_text_offline(file_name, file_bytes, lang=\"por\")\n",
        "doc_ocr[\"doc_hash\"] = doc_hash\n",
        "doc_ocr[\"avg_word_confidence\"] = None   # offline não tem confidence\n",
        "doc_ocr[\"word_confidence_count\"] = 0\n",
        "\n",
        "print(\"Método:\", doc_ocr[\"method\"])\n",
        "print(\"Páginas:\", doc_ocr[\"page_count\"])\n",
        "print(\"\\nAmostra do texto:\\n\", doc_ocr[\"text\"][:800])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9US6vXXLwmAf",
        "outputId": "84a7ebbe-0ada-4343-9e45-54199d35ea54"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Método: PDF_DIGITAL_TEXT\n",
            "Páginas: 1\n",
            "\n",
            "Amostra do texto:\n",
            " CONTRATO DE PRESTAÇÃO DE SERVIÇOS\n",
            "Cliente: João da Silva\n",
            "CPF: 123.456.789-00\n",
            "CNPJ Empresa: 12.345.678/0001-95\n",
            "Data de Emissão: 30/12/2099\n",
            "Data de Vencimento: 01/01/2100\n",
            "Valor do Serviço: R$ 1.234,56\n",
            "Valor Ajustado: R$1234.56\n",
            "Desconto aplicado: 1234,56\n",
            "Taxa adicional: R$ 1.235,00\n",
            "Valor Final TOTAL: R$1234.56 R$ 1.234,56 R$ 1234,56\n",
            "Observação: Este documento foi gerado automaticamente.\n",
            "Itens:\n",
            "•\n",
            "Item 1 - Serviço A - R$ 199,90\n",
            "•\n",
            "Item 2 - Serviço B - R$199.90\n",
            "•\n",
            "Item 3 - Serviço C - 199,90\n",
            "•\n",
            "Item 4 - Serviço D - R$ 200,00\n",
            "•\n",
            "Item 5 - Serviço E - R$199,00\n",
            "•\n",
            "Item 6 - Serviço F - R$ 198,90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def only_digits(x):\n",
        "    return re.sub(r\"\\D\", \"\", x or \"\")\n",
        "\n",
        "def safe_float(s):\n",
        "    if s is None:\n",
        "        return None\n",
        "    s = str(s).strip().replace(\"R$\", \"\").replace(\" \", \"\").replace(\"\\u00A0\", \"\")\n",
        "    if \",\" in s and \".\" in s:\n",
        "        s = s.replace(\".\", \"\").replace(\",\", \".\")\n",
        "    else:\n",
        "        s = s.replace(\",\", \".\")\n",
        "    try:\n",
        "        return float(s)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def parse_date(s):\n",
        "    if not s:\n",
        "        return None\n",
        "    try:\n",
        "        return dateparser.parse(str(s), dayfirst=True).date()\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def find_cpf_cnpj(text):\n",
        "    cpf_pat = r\"\\b(\\d{3}\\.?\\d{3}\\.?\\d{3}-?\\d{2})\\b\"\n",
        "    cnpj_pat = r\"\\b(\\d{2}\\.?\\d{3}\\.?\\d{3}/?\\d{4}-?\\d{2})\\b\"\n",
        "    cpfs = re.findall(cpf_pat, text)\n",
        "    cnpjs = re.findall(cnpj_pat, text)\n",
        "    cpfs = list({only_digits(x) for x in cpfs})\n",
        "    cnpjs = list({only_digits(x) for x in cnpjs})\n",
        "    return cpfs, cnpjs\n",
        "\n",
        "def find_money_values(text):\n",
        "    pat = r\"(?:R\\$\\s*)?(\\d{1,3}(?:\\.\\d{3})*,\\d{2}|\\d+(?:[.,]\\d{2}))\"\n",
        "    vals = re.findall(pat, text)\n",
        "    floats = [safe_float(v) for v in vals]\n",
        "    return [v for v in floats if v is not None]\n",
        "\n",
        "def find_money_raw_tokens(text):\n",
        "    pat = r\"(R\\$\\s*)?(\\d{1,3}(?:\\.\\d{3})*,\\d{2}|\\d+(?:[.,]\\d{2}))\"\n",
        "    return re.findall(pat, text)\n",
        "\n",
        "def find_dates(text):\n",
        "    pats = [\n",
        "        r\"\\b\\d{1,2}[\\/\\-]\\d{1,2}[\\/\\-]\\d{2,4}\\b\",\n",
        "        r\"\\b\\d{4}[\\/\\-]\\d{1,2}[\\/\\-]\\d{1,2}\\b\",\n",
        "    ]\n",
        "    found = set()\n",
        "    for p in pats:\n",
        "        for m in re.findall(p, text):\n",
        "            found.add(m)\n",
        "    parsed = [parse_date(x) for x in found]\n",
        "    return sorted(set([d for d in parsed if d]))\n",
        "\n",
        "def mask_cpf(cpf_digits):\n",
        "    d = only_digits(cpf_digits)\n",
        "    if len(d) == 11:\n",
        "        return f\"***.***.***-{d[-2:]}\"\n",
        "    return \"*\" * max(0, len(d)-2) + d[-2:]\n",
        "\n",
        "def mask_cnpj(cnpj_digits):\n",
        "    d = only_digits(cnpj_digits)\n",
        "    if len(d) == 14:\n",
        "        return f\"**.***.***/****-{d[-2:]}\"\n",
        "    return \"*\" * max(0, len(d)-2) + d[-2:]\n",
        "\n",
        "def mask_text_pii(text):\n",
        "    cpf_pat = r\"\\b(\\d{3}\\.?\\d{3}\\.?\\d{3}-?\\d{2})\\b\"\n",
        "    cnpj_pat = r\"\\b(\\d{2}\\.?\\d{3}\\.?\\d{3}/?\\d{4}-?\\d{2})\\b\"\n",
        "    text = re.sub(cpf_pat, lambda m: mask_cpf(m.group(1)), text)\n",
        "    text = re.sub(cnpj_pat, lambda m: mask_cnpj(m.group(1)), text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "bO-zJaROwqfF"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_cpf(cpf_digits: str) -> bool:\n",
        "    cpf = only_digits(cpf_digits)\n",
        "    if len(cpf) != 11 or cpf == cpf[0]*11:\n",
        "        return False\n",
        "    def dv_calc(base):\n",
        "        s = sum(int(d)*w for d, w in zip(base, range(len(base)+1, 1, -1)))\n",
        "        r = (s*10) % 11\n",
        "        return 0 if r == 10 else r\n",
        "    d1 = dv_calc(cpf[:9])\n",
        "    d2 = dv_calc(cpf[:9] + str(d1))\n",
        "    return cpf.endswith(f\"{d1}{d2}\")\n",
        "\n",
        "def validate_cnpj(cnpj_digits: str) -> bool:\n",
        "    cnpj = only_digits(cnpj_digits)\n",
        "    if len(cnpj) != 14 or cnpj == cnpj[0]*14:\n",
        "        return False\n",
        "    def calc(base, weights):\n",
        "        s = sum(int(d)*w for d, w in zip(base, weights))\n",
        "        r = s % 11\n",
        "        return 0 if r < 2 else 11 - r\n",
        "    w1 = [5,4,3,2,9,8,7,6,5,4,3,2]\n",
        "    w2 = [6] + w1\n",
        "    d1 = calc(cnpj[:12], w1)\n",
        "    d2 = calc(cnpj[:12] + str(d1), w2)\n",
        "    return cnpj.endswith(f\"{d1}{d2}\")"
      ],
      "metadata": {
        "id": "pab3EPuhwtWe"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_extracted_from_text(text, doc_hash):\n",
        "    cpfs, cnpjs = find_cpf_cnpj(text)\n",
        "    money_vals = find_money_values(text)\n",
        "    dates = find_dates(text)\n",
        "    money_tokens = find_money_raw_tokens(text)\n",
        "\n",
        "    return {\n",
        "        \"doc_hash\": doc_hash,\n",
        "        \"cpfs\": cpfs,\n",
        "        \"cnpjs\": cnpjs,\n",
        "        \"money_values\": money_vals[:40],\n",
        "        \"dates\": [d.isoformat() for d in dates[:40]],\n",
        "        \"_money_tokens\": money_tokens,  # interno\n",
        "    }\n",
        "\n",
        "def logistic(z):\n",
        "    return 1.0 / (1.0 + math.exp(-z))\n",
        "\n",
        "def detect_suspicious_value_editing(text, money_vals, money_tokens):\n",
        "    evidence = []\n",
        "\n",
        "    # 1) muitos valores\n",
        "    if len(money_vals) >= 15:\n",
        "        evidence.append(f\"Muitos valores monetários detectados (count={len(money_vals)})\")\n",
        "\n",
        "    # 2) valores muito próximos (diferença <= 1 real)\n",
        "    vals_sorted = sorted(money_vals)\n",
        "    close_pairs = 0\n",
        "    for i in range(1, len(vals_sorted)):\n",
        "        if abs(vals_sorted[i] - vals_sorted[i-1]) <= 1.00:\n",
        "            close_pairs += 1\n",
        "    if close_pairs >= 5:\n",
        "        evidence.append(f\"Muitos valores muito próximos entre si (close_pairs={close_pairs})\")\n",
        "\n",
        "    # 3) mistura de formatos\n",
        "    has_pt, has_en = False, False\n",
        "    for pref, num in money_tokens:\n",
        "        if \".\" in num and \",\" in num:\n",
        "            has_pt = True\n",
        "        elif \".\" in num and \",\" not in num:\n",
        "            has_en = True\n",
        "        elif \",\" in num and \".\" not in num:\n",
        "            has_pt = True\n",
        "    if has_pt and has_en:\n",
        "        evidence.append(\"Mistura de formatos pt-BR e en-US no mesmo documento (pode indicar colagem/edição)\")\n",
        "\n",
        "    # 4) presença de TOTAL + muitos valores\n",
        "    if re.search(r\"\\b(total|valor\\s+total)\\b\", text, flags=re.IGNORECASE) and len(money_vals) >= 8:\n",
        "        evidence.append(\"Palavra-chave de TOTAL presente com muitos valores — revisar consistência do total\")\n",
        "\n",
        "    # 5) ruído: muitos \"R$\" colados (ex: R$123,45 sem espaço) -> pode ser normal, mas sinaliza se exagerado\n",
        "    glued_rs = len(re.findall(r\"R\\$\\d\", text))\n",
        "    if glued_rs >= 10:\n",
        "        evidence.append(f\"Muitos padrões 'R$' colados ao número (count={glued_rs})\")\n",
        "\n",
        "    return evidence\n",
        "\n",
        "def build_flag(rule, severity, points, evidence=None, recommendation=None):\n",
        "    return {\n",
        "        \"rule\": rule,\n",
        "        \"severity\": severity,\n",
        "        \"points\": points,\n",
        "        \"evidence\": evidence or [],\n",
        "        \"recommendation\": recommendation or \"\"\n",
        "    }\n",
        "\n",
        "def fraud_rules_probabilistic(doc_ocr, extracted, cpf_validity, cnpj_validity, seen_hashes=None):\n",
        "    flags = []\n",
        "    z = -2.0  # base baixo risco\n",
        "\n",
        "    text = doc_ocr.get(\"text\",\"\") or \"\"\n",
        "    text_len = len(text)\n",
        "\n",
        "    # Texto muito curto\n",
        "    if text_len < 200:\n",
        "        flags.append(build_flag(\n",
        "            \"VERY_SHORT_TEXT\",\"MEDIUM\",15,\n",
        "            evidence=[f\"text_len={text_len}\"],\n",
        "            recommendation=\"Possível documento incompleto/ilegível. Solicitar reenvio em melhor qualidade.\"\n",
        "        ))\n",
        "        z += 0.8\n",
        "\n",
        "    # OCR confidence (offline = None)\n",
        "    avg_conf = doc_ocr.get(\"avg_word_confidence\")\n",
        "    if avg_conf is not None and avg_conf < 0.85:\n",
        "        flags.append(build_flag(\n",
        "            \"LOW_OCR_CONFIDENCE\",\"MEDIUM\",25,\n",
        "            evidence=[f\"avg_word_confidence={avg_conf:.3f}\"],\n",
        "            recommendation=\"Revisar campos críticos; considerar reenvio do documento.\"\n",
        "        ))\n",
        "        z += 1.2\n",
        "\n",
        "    # CPF/CNPJ inválidos\n",
        "    invalid_cpfs = [c for c,v in cpf_validity.items() if not v]\n",
        "    invalid_cnpjs = [c for c,v in cnpj_validity.items() if not v]\n",
        "\n",
        "    if invalid_cpfs:\n",
        "        flags.append(build_flag(\n",
        "            \"INVALID_CPF\",\"HIGH\",35,\n",
        "            evidence=[f\"cpfs_invalidos={ [mask_cpf(c) for c in invalid_cpfs] }\"],\n",
        "            recommendation=\"Bloquear automação e enviar para revisão humana.\"\n",
        "        ))\n",
        "        z += 1.8\n",
        "\n",
        "    if invalid_cnpjs:\n",
        "        flags.append(build_flag(\n",
        "            \"INVALID_CNPJ\",\"HIGH\",35,\n",
        "            evidence=[f\"cnpjs_invalidos={ [mask_cnpj(c) for c in invalid_cnpjs] }\"],\n",
        "            recommendation=\"Bloquear automação e validar cadastro/empresa.\"\n",
        "        ))\n",
        "        z += 1.8\n",
        "\n",
        "    # Datas futuras\n",
        "    parsed_dates = [parse_date(d) for d in extracted.get(\"dates\", [])]\n",
        "    parsed_dates = [d for d in parsed_dates if d]\n",
        "    today = date.today()\n",
        "    future_dates = [d for d in parsed_dates if d > today]\n",
        "    if future_dates:\n",
        "        flags.append(build_flag(\n",
        "            \"FUTURE_DATE_FOUND\",\"HIGH\",20,\n",
        "            evidence=[f\"datas_futuras={ [d.isoformat() for d in future_dates[:8]] }\"],\n",
        "            recommendation=\"Revisar datas; pode ser adulteração ou OCR incorreto.\"\n",
        "        ))\n",
        "        z += 1.1\n",
        "\n",
        "    # Duplicidade por hash (se tiver histórico)\n",
        "    if seen_hashes is not None and extracted.get(\"doc_hash\") in seen_hashes:\n",
        "        flags.append(build_flag(\n",
        "            \"DUPLICATE_DOCUMENT_HASH\",\"HIGH\",30,\n",
        "            evidence=[f\"hash={extracted.get('doc_hash','')[:16]}...\"],\n",
        "            recommendation=\"Possível reutilização de documento.\"\n",
        "        ))\n",
        "        z += 1.3\n",
        "\n",
        "    # Suspeita de edição de valores\n",
        "    money_vals = extracted.get(\"money_values\", []) or []\n",
        "    money_tokens = extracted.get(\"_money_tokens\", []) or []\n",
        "    susp_ev = detect_suspicious_value_editing(text, money_vals, money_tokens)\n",
        "    if susp_ev:\n",
        "        flags.append(build_flag(\n",
        "            \"SUSPECTED_VALUE_TAMPERING\",\"MEDIUM\",20,\n",
        "            evidence=susp_ev[:6],\n",
        "            recommendation=\"Verificar consistência de itens/totais e sinais de colagem.\"\n",
        "        ))\n",
        "        z += 0.9\n",
        "\n",
        "    # Probabilidade e score\n",
        "    prob = logistic(z)\n",
        "    score = int(round(prob * 100))\n",
        "\n",
        "    # Nível\n",
        "    if score < 25:\n",
        "        level = \"LOW\"\n",
        "    elif score < 60:\n",
        "        level = \"MEDIUM\"\n",
        "    else:\n",
        "        level = \"HIGH\"\n",
        "\n",
        "    # Auditoria (resumo)\n",
        "    sev_order = {\"HIGH\": 0, \"MEDIUM\": 1, \"LOW\": 2}\n",
        "    flags_sorted = sorted(flags, key=lambda f: (sev_order.get(f[\"severity\"], 9), -f[\"points\"]))\n",
        "\n",
        "    lines = [f\"Risco estimado: {score}/100 (prob={prob:.2f}) | Nível: {level}\"]\n",
        "    if flags_sorted:\n",
        "        lines.append(\"Principais achados:\")\n",
        "        for f in flags_sorted[:8]:\n",
        "            ev = \"; \".join(f[\"evidence\"][:3]) if f[\"evidence\"] else \"sem evidência adicional\"\n",
        "            lines.append(f\"- [{f['severity']}] {f['rule']} (+{f['points']}): {ev}\")\n",
        "    else:\n",
        "        lines.append(\"Nenhuma regra crítica acionada.\")\n",
        "    audit_summary = \"\\n\".join(lines)\n",
        "\n",
        "    return score, prob, level, flags_sorted, audit_summary\n",
        "\n",
        "def mask_final_output(final):\n",
        "    # deep copy\n",
        "    out = json.loads(json.dumps(final))\n",
        "\n",
        "    # mascarar preview\n",
        "    if \"text_preview\" in out:\n",
        "        out[\"text_preview\"] = mask_text_pii(out[\"text_preview\"])\n",
        "\n",
        "    # mascarar extracted\n",
        "    ex = out.get(\"extracted\", {})\n",
        "    ex[\"cpfs_masked\"] = [mask_cpf(c) for c in ex.get(\"cpfs\", [])]\n",
        "    ex[\"cnpjs_masked\"] = [mask_cnpj(c) for c in ex.get(\"cnpjs\", [])]\n",
        "    ex.pop(\"cpfs\", None)\n",
        "    ex.pop(\"cnpjs\", None)\n",
        "    ex.pop(\"_money_tokens\", None)\n",
        "\n",
        "    # mascarar validations\n",
        "    vals = out.get(\"validations\", {})\n",
        "    if \"cpf\" in vals:\n",
        "        vals[\"cpf_masked\"] = {mask_cpf(k): v for k, v in vals[\"cpf\"].items()}\n",
        "        vals.pop(\"cpf\", None)\n",
        "    if \"cnpj\" in vals:\n",
        "        vals[\"cnpj_masked\"] = {mask_cnpj(k): v for k, v in vals[\"cnpj\"].items()}\n",
        "        vals.pop(\"cnpj\", None)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "E8zVvWgKwxkG"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = doc_ocr[\"text\"]\n",
        "\n",
        "extracted = build_extracted_from_text(text, doc_hash)\n",
        "\n",
        "cpf_validity = {c: validate_cpf(c) for c in extracted[\"cpfs\"]}\n",
        "cnpj_validity = {c: validate_cnpj(c) for c in extracted[\"cnpjs\"]}\n",
        "\n",
        "score, prob, level, flags, audit_summary = fraud_rules_probabilistic(\n",
        "    doc_ocr, extracted, cpf_validity, cnpj_validity, seen_hashes=set()\n",
        ")\n",
        "\n",
        "from datetime import timezone\n",
        "\n",
        "final = {\n",
        "    \"file_name\": file_name,\n",
        "    \"mode\": \"OFFLINE_DEMO\",\n",
        "    \"doc_hash\": doc_hash,\n",
        "    \"ocr\": {\"method\": doc_ocr[\"method\"], \"page_count\": doc_ocr[\"page_count\"]},\n",
        "    \"extracted\": extracted,\n",
        "    \"validations\": {\"cpf\": cpf_validity, \"cnpj\": cnpj_validity},\n",
        "    \"risk\": {\n",
        "        \"score_0_100\": score,\n",
        "        \"probability_0_1\": prob,\n",
        "        \"level\": level,\n",
        "        \"flags\": flags,\n",
        "        \"audit_summary\": audit_summary\n",
        "    },\n",
        "    \"text_preview\": text[:1200],\n",
        "    \"generated_at\": datetime.now(timezone.utc).isoformat()\n",
        "}\n",
        "\n",
        "final_masked = mask_final_output(final)\n",
        "\n",
        "print(final_masked[\"risk\"][\"audit_summary\"])\n",
        "final_masked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2mB9Ab1w4Am",
        "outputId": "62632317-4d75-4f64-ad62-54fb9f2468df"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Risco estimado: 86/100 (prob=0.86) | Nível: HIGH\n",
            "Principais achados:\n",
            "- [HIGH] INVALID_CPF (+35): cpfs_invalidos=['***.***.***-00']\n",
            "- [HIGH] FUTURE_DATE_FOUND (+20): datas_futuras=['2099-12-30', '2100-01-01']\n",
            "- [MEDIUM] SUSPECTED_VALUE_TAMPERING (+20): Muitos valores monetários detectados (count=17); Muitos valores muito próximos entre si (close_pairs=11); Mistura de formatos pt-BR e en-US no mesmo documento (pode indicar colagem/edição)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'file_name': 'documento_fraude_simulada.pdf',\n",
              " 'mode': 'OFFLINE_DEMO',\n",
              " 'doc_hash': 'a5968e5f7fa1e98887cfcc7139e316b3d3d80aaa23702ac8afd6c50319f44672',\n",
              " 'ocr': {'method': 'PDF_DIGITAL_TEXT', 'page_count': 1},\n",
              " 'extracted': {'doc_hash': 'a5968e5f7fa1e98887cfcc7139e316b3d3d80aaa23702ac8afd6c50319f44672',\n",
              "  'money_values': [123.45,\n",
              "   6.78,\n",
              "   12.34,\n",
              "   5.67,\n",
              "   1234.56,\n",
              "   1234.56,\n",
              "   1234.56,\n",
              "   1235.0,\n",
              "   1234.56,\n",
              "   1234.56,\n",
              "   1234.56,\n",
              "   199.9,\n",
              "   199.9,\n",
              "   199.9,\n",
              "   200.0,\n",
              "   199.0,\n",
              "   198.9],\n",
              "  'dates': ['2099-12-30', '2100-01-01'],\n",
              "  'cpfs_masked': ['***.***.***-00'],\n",
              "  'cnpjs_masked': ['**.***.***/****-95']},\n",
              " 'validations': {'cpf_masked': {'***.***.***-00': False},\n",
              "  'cnpj_masked': {'**.***.***/****-95': True}},\n",
              " 'risk': {'score_0_100': 86,\n",
              "  'probability_0_1': 0.8581489350995123,\n",
              "  'level': 'HIGH',\n",
              "  'flags': [{'rule': 'INVALID_CPF',\n",
              "    'severity': 'HIGH',\n",
              "    'points': 35,\n",
              "    'evidence': [\"cpfs_invalidos=['***.***.***-00']\"],\n",
              "    'recommendation': 'Bloquear automação e enviar para revisão humana.'},\n",
              "   {'rule': 'FUTURE_DATE_FOUND',\n",
              "    'severity': 'HIGH',\n",
              "    'points': 20,\n",
              "    'evidence': [\"datas_futuras=['2099-12-30', '2100-01-01']\"],\n",
              "    'recommendation': 'Revisar datas; pode ser adulteração ou OCR incorreto.'},\n",
              "   {'rule': 'SUSPECTED_VALUE_TAMPERING',\n",
              "    'severity': 'MEDIUM',\n",
              "    'points': 20,\n",
              "    'evidence': ['Muitos valores monetários detectados (count=17)',\n",
              "     'Muitos valores muito próximos entre si (close_pairs=11)',\n",
              "     'Mistura de formatos pt-BR e en-US no mesmo documento (pode indicar colagem/edição)',\n",
              "     'Palavra-chave de TOTAL presente com muitos valores — revisar consistência do total'],\n",
              "    'recommendation': 'Verificar consistência de itens/totais e sinais de colagem.'}],\n",
              "  'audit_summary': \"Risco estimado: 86/100 (prob=0.86) | Nível: HIGH\\nPrincipais achados:\\n- [HIGH] INVALID_CPF (+35): cpfs_invalidos=['***.***.***-00']\\n- [HIGH] FUTURE_DATE_FOUND (+20): datas_futuras=['2099-12-30', '2100-01-01']\\n- [MEDIUM] SUSPECTED_VALUE_TAMPERING (+20): Muitos valores monetários detectados (count=17); Muitos valores muito próximos entre si (close_pairs=11); Mistura de formatos pt-BR e en-US no mesmo documento (pode indicar colagem/edição)\"},\n",
              " 'text_preview': 'CONTRATO DE PRESTAÇÃO DE SERVIÇOS\\nCliente: João da Silva\\nCPF: ***.***.***-00\\nCNPJ Empresa: **.***.***/****-95\\nData de Emissão: 30/12/2099\\nData de Vencimento: 01/01/2100\\nValor do Serviço: R$ 1.234,56\\nValor Ajustado: R$1234.56\\nDesconto aplicado: 1234,56\\nTaxa adicional: R$ 1.235,00\\nValor Final TOTAL: R$1234.56 R$ 1.234,56 R$ 1234,56\\nObservação: Este documento foi gerado automaticamente.\\nItens:\\n•\\nItem 1 - Serviço A - R$ 199,90\\n•\\nItem 2 - Serviço B - R$199.90\\n•\\nItem 3 - Serviço C - 199,90\\n•\\nItem 4 - Serviço D - R$ 200,00\\n•\\nItem 5 - Serviço E - R$199,00\\n•\\nItem 6 - Serviço F - R$ 198,90',\n",
              " 'generated_at': '2026-02-26T11:56:51.682860+00:00'}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "with open(\"report_masked.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(final_masked, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "df_flags = pd.DataFrame(final_masked[\"risk\"][\"flags\"])\n",
        "df_flags.to_csv(\"flags.csv\", index=False)\n",
        "\n",
        "files.download(\"report_masked.json\")\n",
        "files.download(\"flags.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8GETU-CxyQie",
        "outputId": "7c522ffe-1bfb-4048-edaa-13991b104055"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a93b2605-decf-4d28-81e9-beb68ffeb031\", \"report_masked.json\", 3310)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_09fdfe38-ef6c-46a7-a2e1-35a60f1c8d9a\", \"flags.csv\", 681)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}